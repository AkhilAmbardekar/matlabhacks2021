% Solve an Input-Output Fitting problem with a Neural Network
% Script generated by Neural Fitting app
% Created 07-Jul-2021 23:02:37
%
% This script assumes these variables are defined:
%
%   CellPerformance - input data.
%   Para - target data.
function templatePSO(OptVars,Xtrain,Ytrain)
    %x = Para';
    %t = CellPerformance';
    x = Xtrain;
    t = Ytrain;
    
    % Choose a Training Function
    % For a list of all training functions type: help nntrain
    % 'trainlm' is usually fastest.
    % 'trainbr' takes longer but may be better for challenging problems.
    % 'trainscg' uses less memory. Suitable in low memory situations.
    
    trainList = {'trainlm' ,'trainbr', 'trainbfg' ,'traincgb', 'traincgf', 'traingd', 'traingda', 'traingdm', 'traingdx', 'trainoss', 'trainrp', 'trainscg', 'trainb', 'trains'}; %ub 15
    trainF = round(OptVars(4));
    trainFcn = char(trainList{trainF});  % Bayesian Regularization backpropagation.
    
    % Create a Fitting Network
    layer1_size = round(OptVars(2));
    layer2_size = round(OptVars(3));
    if round(OptVars(1)) == 2 
            hiddenLayerSizes = [layer1_size layer2_size];
    else 
      hiddenLayerSizes = [layer1_size];
    end
    net = fitnet(hiddenLayerSizes,trainFcn);
    
    % Choose Input and Output Pre/Post-Processing Functions
    % For a list of all processing functions type: help nnprocess
    net.input.processFcns = {'removeconstantrows','mapminmax'};
    net.output.processFcns = {'removeconstantrows','mapminmax'};
    
    % Setup Division of Data for Training, Validation, Testing
    % For a list of all data division functions type: help nndivision
    net.divideFcn = 'dividerand';  % Divide data randomly
    net.divideMode = 'sample';  % Divide up every sample
    net.divideParam.trainRatio = 70/100;
    net.divideParam.valRatio = 15/100;
    net.divideParam.testRatio = 15/100;
    
    actFunc = {'logsig', 'tansig', 'satlins','purelin', 'poslin', 'satlin', 'compet', 'elliotsig', 'hardlim', 'hardlims', 'netinv', 'radbas', 'radbasn', 'softmax', 'tribas'}; %ub 15
    actF1 = round(OptVars(8));
    actF2 = round(OptVars(9));
    TrainFcn1 = actFunc(actF1);
    TrainFcn2 = actFunc(actF2);
    
    if round(OptVars(1)) == 2  
           net.layers{1}.transferFcn = char(TrainFcn1);  % Hidden layer 1
           net.layers{2}.transferFcn = char(TrainFcn2);  % Hidden layer 2
           net.layers{3}.transferFcn = 'purelin';  % Output layer
    else 
           net.layers{1}.transferFcn = char(TrainFcn1);  % Hidden layer 
           net.layers{2}.transferFcn = 'purelin';
    end
    %net.performParam.normalization = 'standard';
    net.trainParam.lr = OptVars(6);
    net.trainParam.mc = OptVars(7);
    net.trainParam.epochs = round(OptVars(5));
    
    % Choose a Performance Function
    % For a list of all performance functions type: help nnperformance
    net.performFcn = 'mse';  % Mean Squared Error
    
    % Choose Plot Functions
    % For a list of all plot functions type: help nnplot
    net.plotFcns = {'plotperform','plottrainstate','ploterrhist', ...
        'plotregression', 'plotfit'};
    
    % Train the Network
    [net,tr] = train(net,x,t);
    
    % Test the Network
    y = net(x);
    e = gsubtract(t,y);
    performance = perform(net,t,y)
    
    % Recalculate Training, Validation and Test Performance
    trainTargets = t .* tr.trainMask{1};
    valTargets = t .* tr.valMask{1};
    testTargets = t .* tr.testMask{1};
    trainPerformance = perform(net,trainTargets,y)
    valPerformance = perform(net,valTargets,y)
    testPerformance = perform(net,testTargets,y)
    
    %bayesopt(perform, [net,valTargets,y])
    
    % View the Network
    view(net)
    %hyperparameters(fitnet,Para, CellPerformance)
    % Plots
    % Uncomment these lines to enable various plots.
    %figure, plotperform(tr)
    %figure, plottrainstate(tr)
    %figure, ploterrhist(e)
    %figure, plotregression(t,y)
    %figure, plotfit(net,x,t)
    
    % Deployment
    % Change the (false) values to (true) to enable the following code blocks.
    % See the help for each generation function for more information.
    if (true)
        % Generate MATLAB function for neural network for application
        % deployment in MATLAB scripts or with MATLAB Compiler and Builder
        % tools, or simply to examine the calculations your trained neural
        % network performs.
        genFunction(net,'NNPSO');
        y = myNeuralNetworkFunction(x);
    end
    if (false)
        % Generate a matrix-only MATLAB function for neural network code
        % generation with MATLAB Coder tools.
        genFunction(net,'myNeuralNetworkFunction','MatrixOnly','yes');
        y = myNeuralNetworkFunction(x);
    end
    if (false)
        % Generate a Simulink diagram for simulation or deployment with.
        % Simulink Coder tools.
        gensim(net);
    end
end
%function valP = objFunc(net, valTargets, y)